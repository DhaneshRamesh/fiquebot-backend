from fastapi import FastAPI, Request, Form, BackgroundTasks, HTTPException, Response, StreamingResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import PlainTextResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import List, Optional
import os
import httpx
import re
import json
import uuid
import time
import asyncio
from dotenv import load_dotenv
from twilio.rest import Client
from azure.cosmos import CosmosClient, PartitionKey
from azure_search import search_articles
from utils import extract_metadata_from_message, needs_form
import xml.sax.saxutils as saxutils
from elevenlabs.client import ElevenLabs
from elevenlabs import VoiceSettings
from azure.storage.blob import BlobServiceClient, ContentSettings
from cosmos_client import update_preferences

# Load environment variables
load_dotenv(dotenv_path=".env.production")

AZURE_OPENAI_ENDPOINT = os.environ.get("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_KEY = os.environ.get("AZURE_OPENAI_KEY")
AZURE_OPENAI_MODEL = os.environ.get("AZURE_OPENAI_MODEL")
AZURE_OPENAI_API_VERSION = os.environ.get("AZURE_OPENAI_PREVIEW_API_VERSION", "2024-05-01-preview")
AZURE_WHISPER_MODEL = os.environ.get("AZURE_WHISPER_MODEL", "whisper-1")

TWILIO_ACCOUNT_SID = os.environ.get("TWILIO_ACCOUNT_SID")
TWILIO_AUTH_TOKEN = os.environ.get("TWILIO_AUTH_TOKEN")
TWILIO_PHONE_NUMBER = os.environ.get("TWILIO_PHONE_NUMBER", "whatsapp:+447488880990")
TWILIO_VOICE_NUMBER = os.environ.get("TWILIO_VOICE_NUMBER")

ELEVENLABS_API_KEY = os.environ.get("ELEVENLABS_API_KEY")
ELEVENLABS_VOICE_ID = os.environ.get("ELEVENLABS_VOICE_ID", "21m00Tcm4TlvDq8ikWAM")

AZURE_STORAGE_CONNECTION_STRING = os.environ.get("AZURE_STORAGE_CONNECTION_STRING")

required_vars = [
    "AZURE_OPENAI_ENDPOINT", "AZURE_OPENAI_KEY", "AZURE_OPENAI_MODEL",
    "TWILIO_ACCOUNT_SID", "TWILIO_AUTH_TOKEN",
    "AZURE_STORAGE_CONNECTION_STRING",
    "COSMOS_DB_ENDPOINT", "COSMOS_DB_KEY"
]
for var in required_vars:
    if not os.environ.get(var):
        raise EnvironmentError(f"Missing required environment variable: {var}")

app = FastAPI()

conversation_history = {}

app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://kind-island-057bb3903.6.azurestaticapps.net"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.mount("/static", StaticFiles(directory="static"), name="static")

class Message(BaseModel):
    role: str
    content: str

class ConversationRequest(BaseModel):
    messages: Optional[List[Message]] = []
    session_id: Optional[str] = None

class FeedbackRequest(BaseModel):
    user_id: str
    fact_id: str
    liked: bool

@app.get("/")
async def root():
    return {"message": "Backend online!"}

async def transcribe_audio(audio_url: str) -> str:
    """
    Transcribe audio from the given URL using Azure OpenAI Whisper.
    """
    print(f"üéôÔ∏è Starting transcription for audio URL: {audio_url}")
    try:
        async with httpx.AsyncClient(timeout=30, follow_redirects=True) as client:
            print(f"üì• Downloading audio from {audio_url}")
            response = await client.get(audio_url, auth=(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN))
            if response.is_redirect:
                print(f"üîÑ Redirected to: {response.headers.get('location')}")
            response.raise_for_status()
            audio_content = response.content
            print(f"‚úÖ Audio downloaded successfully, size: {len(audio_content)} bytes")

            headers = {
                "Content-Type": "multipart/form-data",
                "api-key": AZURE_OPENAI_KEY
            }
            files = {
                "file": ("audio.mp3", audio_content, "audio/mpeg")
            }
            data = {
                "model": AZURE_WHISPER_MODEL
            }
            print(f"üì§ Sending audio to Whisper model: {AZURE_WHISPER_MODEL}")
            response = await client.post(
                f"{AZURE_OPENAI_ENDPOINT}/openai/deployments/{AZURE_WHISPER_MODEL}/audio/transcriptions?api-version={AZURE_OPENAI_API_VERSION}",
                headers={"api-key": AZURE_OPENAI_KEY},
                files=files,
                data=data
            )
            response.raise_for_status()
            result = response.json()
            print(f"üéôÔ∏è Full transcription response: {result}")
            return result.get("text", "")
    except Exception as e:
        print(f"‚ùå Error transcribing audio: {str(e)}")
        return ""

async def conversation_logic(messages, metadata):
    try:
        cleaned_messages = [{"role": m["role"], "content": m["content"]} for m in messages]
        user_question = cleaned_messages[-1]['content']
        print(f"üß† Calling OpenAI with messages: {cleaned_messages}")
        
        def extract_keywords(text):
            words = re.findall(r'\w+', text.lower())
            stopwords = {"the", "of", "and", "in", "on", "is", "to", "a"}
            keywords = [w for w in words if w not in stopwords]
            return " ".join(keywords[:10])
        
        keywords = extract_keywords(user_question)
        search_contexts = search_articles(keywords) or []
        print(f"üîç Search query: {keywords}")
        print(f"üìÑ Articles returned: {len(search_contexts)}")
        print(f"üîç Search context: {search_contexts}")
        
        fallback_phrases = [
            "yes", "yeah", "sure", "go ahead", "please do", "try general", "fallback", "try again",
            "use gpt", "search online", "search web", "do it", "okay", "alright", "continue",
            "that‚Äôs fine", "proceed", "give me an answer", "show me anyway"
        ]
        fallback_flag = any(
            any(phrase in m['content'].lower() for phrase in fallback_phrases)
            for m in messages[-2:]
        )
        
        if not search_contexts and not fallback_flag:
            return [{"role": "assistant", "content": "ü§ñ I couldn‚Äôt find anything in our articles. Would you like to try a general answer instead?"}]
        
        if fallback_flag or search_contexts:
            if search_contexts:
                context_block = "\n\n".join([
                    f"{item['snippet']}\n\nSource: {item['title']} ({item['url']})"
                    for item in search_contexts if isinstance(item, dict) and all(k in item for k in ["snippet", "title", "url"])
                ]) or "\n\n".join([str(item) for item in search_contexts])
                cleaned_messages[-1] = {
                    "role": "user",
                    "content": f"""Use the following context to answer the question. Cite the article title and URL explicitly.\n\nContext:\n{context_block}\n\nQuestion:\n{user_question}"""
                }
            else:
                cleaned_messages[-1] = {
                    "role": "user",
                    "content": f"Answer the following question in a friendly, conversational tone: {user_question}"
                }
        
        headers = {"Content-Type": "application/json", "api-key": AZURE_OPENAI_KEY}
        body = {
            "messages": cleaned_messages,
            "temperature": 0.7,
            "top_p": 0.95,
            "frequency_penalty": 0,
            "presence_penalty": 0,
            "max_tokens": 500,
            "stream": False,
        }
        
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(
                f"{AZURE_OPENAI_ENDPOINT}/openai/deployments/{AZURE_OPENAI_MODEL}/chat/completions?api-version={AZURE_OPENAI_API_VERSION}",
                headers=headers,
                json=body
            )
            response.raise_for_status()
        
        result = response.json()
        print(f"‚úÖ OpenAI response: {result}")
        
        if not result or not result.get("choices") or not result["choices"][0].get("message"):
            print("‚ö†Ô∏è OpenAI response is empty or malformed")
            return [{"role": "assistant", "content": "‚ö†Ô∏è I couldn‚Äôt generate a response."}]
        
        return [result["choices"][0]["message"]]
    
    except Exception as e:
        print(f"‚ùå Error in conversation_logic: {str(e)}")
        import traceback
        traceback.print_exc()
        return [{"role": "assistant", "content": "‚ö†Ô∏è Sorry, there was an error processing your message."}]

async def stream_response(messages, session_id):
    response_data = {
        "choices": [{"messages": messages}],
        "session_id": session_id
    }
    yield json.dumps(response_data) + "\n"
    yield "\n"

@app.post("/conversation")
async def conversation_endpoint(request: Request):
    try:
        payload = await request.json()
        messages_data = payload.get("messages", [])
        session_id = payload.get("session_id", str(uuid.uuid4()))
        print(f"üì© Received payload: {payload}, Session ID: {session_id}")
        
        if not messages_data:
            return StreamingResponse(
                stream_response(
                    [{"role": "assistant", "content": "üëã Welcome! Before we begin, could you please tell me your *country* and *phone number*?"}],
                    session_id
                ),
                media_type="text/event-stream"
            )
        
        valid_messages = [
            Message(role=msg["role"], content=msg["content"])
            for msg in messages_data
            if isinstance(msg, dict) and msg.get("role") and msg.get("content")
        ]
        
        if not valid_messages:
            return StreamingResponse(
                stream_response(
                    [{"role": "assistant", "content": "‚ö†Ô∏è Invalid message format."}],
                    session_id
                ),
                media_type="text/event-stream"
            )
        
        if session_id not in conversation_history:
            conversation_history[session_id] = []
        
        latest_user_message = {"role": valid_messages[-1].role, "content": valid_messages[-1].content}
        conversation_history[session_id].append(latest_user_message)
        print(f"üìú Conversation history for session {session_id}: {conversation_history[session_id]}")
        
        all_user_text = " ".join([m.content for m in valid_messages if m.role == "user"])
        metadata = {
            "phone": payload.get("phone"),
            "country": payload.get("country"),
            "language": payload.get("language")
        }
        
        if not metadata["phone"] or not metadata["country"]:
            async with httpx.AsyncClient(timeout=10) as client:
                meta_response = await client.post(
                    f"{request.base_url}extract_metadata",
                    json={"text": all_user_text}
                )
            if meta_response.status_code == 200:
                metadata = meta_response.json()
                print(f"üìã Extracted metadata: {metadata}")
        
        if len(conversation_history[session_id]) == 1 and needs_form(metadata):
            missing_fields = [k for k, v in metadata.items() if v is None]
            return StreamingResponse(
                stream_response(
                    [{"role": "assistant", "content": f"‚ö†Ô∏è I need more info to help you: missing {', '.join(missing_fields)}. Could you please provide it?"}],
                    session_id
                ),
                media_type="text/event-stream"
            )
        
        if len(conversation_history[session_id]) == 2 and (metadata["phone"] and metadata["country"]):
            response_message = {
                "role": "assistant",
                "content": (
                    f"""‚úÖ Got it! Here's what I understood:\n\n"""
                    f"- Country: {metadata['country']}\n"
                    f"- Language: {metadata['language']}\n"
                    f"- Phone: {metadata['phone']}\n\n"
                    f"üìò Now, what would you like to ask about Fique?"
                )
            }
            conversation_history[session_id].append(response_message)
            return StreamingResponse(
                stream_response([response_message], session_id),
                media_type="text/event-stream"
            )
        
        result = await conversation_logic(conversation_history[session_id], metadata)
        conversation_history[session_id].append({"role": "assistant", "content": result[0]["content"]})
        return StreamingResponse(
            stream_response(result, session_id),
            media_type="text/event-stream"
        )
    
    except Exception as e:
        print(f"‚ùå Error during conversation: {str(e)}")
        import traceback
        traceback.print_exc()
        return StreamingResponse(
            stream_response(
                [{"role": "assistant", "content": "‚ö†Ô∏è Sorry, there was an error processing your message."}],
                session_id
            ),
            media_type="text/event-stream"
        )

async def cleanup_audio(audio_path, delay=300):
    import time
    time.sleep(delay)
    if os.path.exists(audio_path):
        os.remove(audio_path)
        print(f"üóëÔ∏è Deleted audio file: {audio_path}")

@app.get("/audio/{filename}")
async def serve_audio(filename: str):
    start_time = time.time()
    audio_path = os.path.join("static/audio", filename)
    if not os.path.exists(audio_path):
        print(f"‚ùå Audio file not found: {audio_path}")
        raise HTTPException(status_code=404, detail="Audio file not found")
    print(f"üéµ Serving audio file: {audio_path}")
    response = FileResponse(audio_path, media_type="audio/mpeg")
    end_time = time.time()
    print(f"‚è±Ô∏è Audio serving took {end_time - start_time:.2f} seconds")
    return response

async def upload_to_public_hosting(audio_path: str, audio_filename: str) -> str:
    """
    Uploads the audio file to Azure Blob Storage and returns a public URL.
    Files are stored in the 'audio-files' container with public read access.
    """
    start_time = time.time()
    try:
        blob_service_client = BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)
        container_name = "audio-files"
        blob_name = audio_filename

        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)

        content_settings = ContentSettings(content_type="audio/mpeg")

        with open(audio_path, "rb") as f:
            await asyncio.to_thread(blob_client.upload_blob, f, overwrite=True, content_settings=content_settings)

        public_url = f"https://{blob_service_client.account_name}.blob.core.windows.net/{container_name}/{blob_name}"

        async with httpx.AsyncClient(timeout=5) as client:
            response = await client.head(public_url)
            if response.status_code != 200:
                print(f"‚ùå Blob URL is not accessible: {response.status_code}")
                raise Exception(f"Uploaded audio is not publicly accessible: {response.status_code}")

    except Exception as e:
        print(f"‚ùå Azure Blob Storage upload error: {str(e)}")
        raise
    finally:
        blob_service_client.close()

    end_time = time.time()
    print(f"üì§ Uploaded {audio_path} to Azure Blob Storage in {end_time - start_time:.2f} seconds")
    print(f"‚úÖ Public URL: {public_url}")
    return public_url

@app.post("/twilio-webhook")
async def handle_whatsapp(request: Request, background_tasks: BackgroundTasks, From: str = Form(...), Body: str = Form(...)):
    try:
        form = await request.form()
        user_input = Body.strip().lower()
        media_url = form.get("MediaUrl0")
        media_content_type = form.get("MediaContentType0")

        print(f"üì© Received WhatsApp message from {From}: Body={Body}, Media={media_url}")

        # Check for feedback in user_input (e.g., "I liked fact001" or "I dislike fact004")
        feedback_pattern = r"(?:i\s+)?(?:like|liked|dislike|disliked)\s+(fact\d+)"
        feedback_match = re.search(feedback_pattern, user_input)
        feedback_processed = False
        feedback_response = ""

        if feedback_match:
            fact_id = feedback_match.group(1)
            liked = "like" in feedback_match.group(0).lower()
            try:
                update_preferences(From, fact_id, liked)
                feedback_response = f"‚úÖ Recorded your {'like' if liked else 'dislike'} for {fact_id}."
                feedback_processed = True
                print(f"‚úÖ Feedback processed for {From}: fact_id={fact_id}, liked={liked}")
            except Exception as e:
                print(f"‚ùå Error processing feedback: {str(e)}")
                feedback_response = "‚ö†Ô∏è Sorry, I couldn‚Äôt save your feedback."

        voice_phrases = ["send voice", "reply in audio", "voice answer", "audio response"]
        is_voice_request = any(phrase in user_input for phrase in voice_phrases)
        is_voice_message = media_url and media_content_type and "audio" in media_content_type.lower()

        if is_voice_message and media_url:
            print(f"üéôÔ∏è Initiating transcription for voice message")
            transcribed_text = await transcribe_audio(media_url)
            user_input = transcribed_text.strip().lower() if transcribed_text else "[Voice message]"
            print(f"üéôÔ∏è Transcribed voice message: {user_input}")

            # Check for feedback in transcribed text
            feedback_match = re.search(feedback_pattern, user_input)
            if feedback_match:
                fact_id = feedback_match.group(1)
                liked = "like" in feedback_match.group(0).lower()
                try:
                    update_preferences(From, fact_id, liked)
                    feedback_response = f"‚úÖ Recorded your {'like' if liked else 'dislike'} for {fact_id}."
                    feedback_processed = True
                    print(f"‚úÖ Feedback processed for {From}: fact_id={fact_id}, liked={liked}")
                except Exception as e:
                    print(f"‚ùå Error processing feedback: {str(e)}")
                    feedback_response = "‚ö†Ô∏è Sorry, I couldn‚Äôt save your feedback."

        if user_input == "reset":
            if From in conversation_history:
                del conversation_history[From]
                print(f"üîÑ Reset conversation history for {From}")
            text_reply = "‚úÖ Conversation reset. Let‚Äôs start fresh! Please tell me your country and phone number."
        else:
            if From not in conversation_history:
                conversation_history[From] = []
            
            conversation_history[From].append({"role": "user", "content": user_input})
            print(f"üìú Full conversation history for {From}: {conversation_history[From]}")
            
            metadata = {"phone": From, "country": "auto", "language": "en"}
            try:
                result = await conversation_logic(conversation_history[From], metadata)
                text_reply = result[0]["content"]
                if feedback_processed:
                    text_reply = f"{feedback_response}\n\n{text_reply}"
                conversation_history[From].append({"role": "assistant", "content": text_reply})
            except Exception as e:
                print(f"‚ùå Error in twilio-webhook conversation_logic: {str(e)}")
                text_reply = "‚ö†Ô∏è Sorry, something went wrong."
                if feedback_processed:
                    text_reply = f"{feedback_response}\n\n{text_reply}"

        if not TWILIO_ACCOUNT_SID or not TWILIO_AUTH_TOKEN:
            print(f"‚ùå Twilio credentials missing: SID={TWILIO_ACCOUNT_SID}, Token={TWILIO_AUTH_TOKEN}")
            return PlainTextResponse("Twilio credentials missing", status_code=500)
        
        client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)
        if (is_voice_request or is_voice_message) and ELEVENLABS_API_KEY and ELEVENLABS_VOICE_ID:
            text_reply = text_reply[:150]
            try:
                elevenlabs_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
                audio_dir = "static/audio"
                os.makedirs(audio_dir, exist_ok=True)
                audio_filename = f"{uuid.uuid4()}.mp3"
                audio_path = os.path.join(audio_dir, audio_filename)
                
                audio_bytes = elevenlabs_client.text_to_speech.convert(
                    voice_id=ELEVENLABS_VOICE_ID,
                    text=text_reply,
                    voice_settings=VoiceSettings(
                        stability=0.5,
                        similarity_boost=0.5
                    ),
                    output_format="mp3_44100_128"
                )
                
                with open(audio_path, "wb") as f:
                    for chunk in audio_bytes:
                        if chunk:
                            f.write(chunk)
                
                file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
                print(f"üìè Audio file size: {file_size_mb:.2f} MB")
                if file_size_mb > 16:
                    raise Exception("Audio file exceeds WhatsApp 16MB limit")
                
                audio_url = await upload_to_public_hosting(audio_path, audio_filename)
                
                if not os.path.exists(audio_path):
                    raise Exception("Audio file not found after creation")
                
                message = client.messages.create(
                    media_url=[audio_url],
                    from_=TWILIO_PHONE_NUMBER,
                    to=From
                )
                updated_message = client.messages(message.sid).fetch()
                print(f"üì§ Audio message status: {updated_message.status}, SID: {message.sid}, URL: {audio_url}")
                if updated_message.status in ["failed", "undelivered"]:
                    print(f"‚ùå Audio delivery failed with error: {updated_message.error_code} - {updated_message.error_message}")
                    message = client.messages.create(
                        body=text_reply,
                        from_=TWILIO_PHONE_NUMBER,
                        to=From
                    )
                    print(f"‚úÖ Fallback text message sent to {From}, SID: {message.sid}")
                else:
                    background_tasks.add_task(cleanup_audio, audio_path)
                    print(f"‚úÖ Audio message sent to {From}, SID: {message.sid}, URL: {audio_url}")
            except Exception as e:
                print(f"‚ùå Error generating audio with ElevenLabs: {str(e)}")
                message = client.messages.create(
                    body=text_reply,
                    from_=TWILIO_PHONE_NUMBER,
                    to=From
                )
                print(f"‚úÖ Fallback text message sent to {From}, SID: {message.sid}")
        else:
            message = client.messages.create(
                body=text_reply,
                from_=TWILIO_PHONE_NUMBER,
                to=From
            )
            print(f"‚úÖ Text message sent to {From}, SID: {message.sid}")
        
        return PlainTextResponse("")
    
    except Exception as e:
        print(f"‚ùå Critical error in twilio-webhook: {str(e)}")
        import traceback
        traceback.print_exc()
        return PlainTextResponse("", status_code=500)

@app.post("/feedback")
async def process_feedback(feedback: FeedbackRequest):
    try:
        # Validate user_id format (allow whatsapp:+... or uuid-...)
        if not (feedback.user_id.startswith("whatsapp:") or feedback.user_id.startswith("uuid-")):
            raise HTTPException(status_code=400, detail="Invalid user_id format")
        update_preferences(feedback.user_id, feedback.fact_id, feedback.liked)
        return {"status": "success"}
    except Exception as e:
        print(f"‚ùå Error in process_feedback: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/extract_metadata")
async def extract_metadata_via_openai(request: Request):
    data = await request.json()
    user_input = data.get("text")
    if not user_input:
        return {"error": "No text provided."}
    openai_body = {
        "messages": [
            {
                "role": "system",
                "content": "You are a metadata extraction assistant. Extract phone number, country, and language from the text below. Respond strictly in this JSON format: { \"phone\": \"\", \"country\": \"\", \"language\": \"\", \"confidence\": 0.95 }"
            },
            {"role": "user", "content": user_input}
        ],
        "temperature": 0,
        "max_tokens": 100,
        "top_p": 1,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "stream": False,
    }
    headers = {
        "Content-Type": "application/json",
        "api-key": AZURE_OPENAI_KEY
    }
    async with httpx.AsyncClient(timeout=15) as client:
        response = await client.post(
            f"{AZURE_OPENAI_ENDPOINT}/openai/deployments/{AZURE_OPENAI_MODEL}/chat/completions?api-version={AZURE_OPENAI_API_VERSION}",
            headers=headers,
            json=openai_body
        )
    try:
        result = response.json()
        reply = result["choices"][0]["message"]["content"]
        return json.loads(reply)
    except Exception as e:
        return {
            "error": "Failed to parse OpenAI response.",
            "raw": reply,
            "details": str(e)
        }

@app.post("/voice", response_class=Response)
async def voice():
    twiml = '''<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Gather input="speech" action="/process_speech" method="POST" timeout="5">
        <Say>Hello, you're now connected to the Fique AI assistant. Please say something after the beep.</Say>
    </Gather>
    <Say>Sorry, I didn't catch that. Goodbye!</Say>
</Response>'''
    return Response(content=twiml, media_type="application/xml")

@app.post("/process_speech", response_class=Response)
async def process_speech(request: Request, background_tasks: BackgroundTasks):
    try:
        form = await request.form()
        user_input = form.get("SpeechResult", "").strip()
        phone = form.get("From", "unknown")

        if not user_input:
            twiml = '''<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Say>Sorry, I didn't hear anything. Please try again.</Say>
</Response>'''
            return Response(content=twiml, media_type="application/xml")

        if phone not in conversation_history:
            conversation_history[phone] = []
        conversation_history[phone].append({"role": "user", "content": user_input})

        metadata = {"phone": phone, "country": "auto", "language": "en"}
        result = await conversation_logic(conversation_history[phone], metadata)
        reply_text = saxutils.escape(result[0]["content"])

        conversation_history[phone].append({"role": "assistant", "content": reply_text})

        print(f"üìû Voice interaction from {phone}: Input={user_input}, Reply={reply_text}")

        twiml = f'''<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Say>{reply_text}</Say>
</Response>'''
        return Response(content=twiml, media_type="application/xml")
    except Exception as e:
        print(f"‚ùå Error in process_speech: {str(e)}")
        twiml = '''<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Say>Sorry, an error occurred. Please try again later.</Say>
</Response>'''
        return Response(content=twiml, media_type="application/xml")

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run("main:app", host="0.0.0.0", port=port)
